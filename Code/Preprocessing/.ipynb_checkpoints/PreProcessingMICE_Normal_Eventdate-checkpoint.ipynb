{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b406626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries \n",
    "import pandas as pd\n",
    "from pandas.testing import assert_frame_equal\n",
    "import numpy as np\n",
    "import csv \n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#pip install fancyimpute\n",
    "from fancyimpute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d2b1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print display settings\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_columns', 5000)\n",
    "pd.set_option('display.width', 5000)\n",
    "pd.set_option('display.max_colwidth', 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee9c536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move up 2 directories\n",
    "data_directory = '../..' \n",
    "\n",
    "# Load the CSV files\n",
    "asthma_df = pd.read_csv(os.path.join(data_directory, 'Data', 'astma.csv'))\n",
    "healthy_df = pd.read_csv(os.path.join(data_directory, 'Data', 'healthy_parsed.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84e2e09",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6455bae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b932ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "asthma_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc9d3e8",
   "metadata": {},
   "source": [
    "# Issue with HR columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8773c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the asthma dataset there seems to be a problem with HR00 to HR23\n",
    "# The heart rate goes above a million sometimes\n",
    "# It seems like the first couple digits correspond with the expected heart rate.\n",
    "# 2 cases: HR below 100 and HR above 100\n",
    "\n",
    "# Loop through each column in the dataframe\n",
    "for col in asthma_df.loc[:, \"HR00\":\"HR23\"]:\n",
    "    for i in range(len(asthma_df[col])):\n",
    "        if asthma_df.loc[i, col] > 1000:\n",
    "            # Take first 2 digits of float\n",
    "            first_2_digits = str(asthma_df.loc[i, col])[:2]\n",
    "            temp_number = float(first_2_digits)\n",
    "            # If heart rate lower than 20 it means it should be greater than 100 (assuming heart rates < 200)\n",
    "            if temp_number < 20:\n",
    "                val = str(asthma_df.loc[i, col])[:3] + '.' + str(asthma_df.loc[i, col])[3]\n",
    "                asthma_df.loc[i, col] = float(val)\n",
    "            else:\n",
    "                val = str(asthma_df.loc[i, col])[:2] + '.' + str(asthma_df.loc[i, col])[2]\n",
    "                asthma_df.loc[i, col] = float(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f999c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that it works \n",
    "asthma_df.loc[:, \"HR00\":\"HR23\"].head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa4d4b7",
   "metadata": {},
   "source": [
    "# Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9310227b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject 2429672 has no data about gender, sports and urbanisation \n",
    "# asthma_df = asthma_df[asthma_df['SubjectNr'] != 2429672]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974a053e",
   "metadata": {},
   "source": [
    "# Alligning column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab97571",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Renaming columns (allignment)\n",
    "asthma_df = asthma_df.rename(columns={'Gender': 'sex'})\n",
    "asthma_df = asthma_df.rename(columns={'Weight': 'weight'})\n",
    "asthma_df = asthma_df.rename(columns={'Height': 'height'})\n",
    "\n",
    "# What grade they are in\n",
    "healthy_df = healthy_df.rename(columns={'school_year_final': 'school_year'})\n",
    "asthma_df = asthma_df.rename(columns={'school_year_edit': 'school_year'})\n",
    "\n",
    "# Wheter they do a sport\n",
    "asthma_df = asthma_df.rename(columns={'Sports': 'sportsyesno'})\n",
    "\n",
    "# Note there are 2 urbanisations\n",
    "asthma_df = asthma_df.rename(columns={'urbanisation2': 'urbanisation'})\n",
    "\n",
    "# pedsql\n",
    "asthma_df = asthma_df.rename(columns={'BASELINE_PedsQL_score': 'PedsQL_score_baseline'})\n",
    "\n",
    "# Note healthy_df doesn't have all wear variables (it only has the grped vars)\n",
    "# Asthma_df doesnt have wear05H lets compute it based on the other wear vars\n",
    "asthma_df['wear05H'] = (asthma_df.loc[:, 'wear00':'wear05'] == 1).mean(axis=1) * 100\n",
    "\n",
    "# No temperature in asthma_df but is in healthy_df?\n",
    "# Drop the col\n",
    "healthy_df = healthy_df.drop('BODY_TEMPERATURE_DEG_C', axis=1)\n",
    "\n",
    "# No blood preassure in asthma_df but is in healthy_df?\n",
    "# drop in healthy\n",
    "healthy_df = healthy_df.drop('DIASTOLIC_BLOOD_PRESSURE_MMHG', axis=1)\n",
    "healthy_df = healthy_df.drop('SYSTOLIC_BLOOD_PRESSURE_MMHG', axis=1)\n",
    "\n",
    "# Note that WEIGHT_KG is a daily meassurement in healthy_df\n",
    "# in asthma_df this meassurement is only taken at begin and end of the study period\n",
    "# Also missing data is 87% lets drop this col\n",
    "healthy_df = healthy_df.drop('WEIGHT_KG', axis=1)\n",
    "\n",
    "# I am assuming these columns are the same (bedtimeReport and waketimeReport not in legend))\n",
    "asthma_df = asthma_df.rename(columns={'bedtimeReport': 'sleeptime'})\n",
    "asthma_df = asthma_df.rename(columns={'waketimeReport': 'waketime'})\n",
    "\n",
    "# Create a new column with the hourly categories starting from 0 to 23\n",
    "hour_mapping = {i: i for i in range(24)}\n",
    "\n",
    "# Converting to datetime\n",
    "healthy_df['sleeptime'] = pd.to_datetime(healthy_df['sleeptime'])\n",
    "asthma_df['sleeptime'] = pd.to_datetime(asthma_df['sleeptime'])\n",
    "healthy_df['waketime'] = pd.to_datetime(healthy_df['waketime'])\n",
    "asthma_df['waketime'] = pd.to_datetime(asthma_df['waketime'])\n",
    "\n",
    "# Setting hourly value\n",
    "healthy_df['sleeptime'] = healthy_df['sleeptime'].dt.hour\n",
    "asthma_df['sleeptime'] = asthma_df['sleeptime'].dt.hour\n",
    "healthy_df['waketime'] = healthy_df['waketime'].dt.hour\n",
    "asthma_df['waketime'] = asthma_df['waketime'].dt.hour\n",
    "\n",
    "# predicted_fvc_best, predicted_fev1_best, predicted_fev1_ratio_best\n",
    "# All of these not in asthma\n",
    "healthy_df = healthy_df.drop('predicted_fvc_best', axis=1)\n",
    "healthy_df = healthy_df.drop('predicted_fev1_best', axis=1)\n",
    "healthy_df = healthy_df.drop('predicted_fev1_ratio_best', axis=1)\n",
    "\n",
    "# Screentime, values need to be alligned \n",
    "# Alignment dictionary\n",
    "alignment_dict = {\n",
    "    '0': '0',\n",
    "    'D. 2 uur tot 4 uur': '2-4 hours',\n",
    "    'A. 0 tot 30 minuten': '0-30 min',\n",
    "    'C. 1 uur tot 2 uur': '1-2 hours',\n",
    "    'B. 30 tot 60 minuten': '0.5-1 hours',\n",
    "    'E. Meer dan 4 uur': '> 4 hours'\n",
    "}\n",
    "\n",
    "# Rename values in the first dataframe based on the alignment dictionary\n",
    "asthma_df['screentime'] = asthma_df['screentime'].replace(alignment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaad9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de4a2fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "asthma_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14f503b",
   "metadata": {},
   "source": [
    "# Delete colums (that are useless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb10c649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just an index we dont need it\n",
    "healthy_df = healthy_df.drop('Index', axis=1)\n",
    "\n",
    "# Subjects number are not relevant for predicting\n",
    "healthy_df = healthy_df.drop('SubjectNr', axis=1)\n",
    "\n",
    "# We only have ethnicity in healthy_df\n",
    "healthy_df = healthy_df.drop('ethnicity', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc56a96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b1d814",
   "metadata": {},
   "outputs": [],
   "source": [
    "asthma_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c176690f",
   "metadata": {},
   "source": [
    "# One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d9231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the possible values of different columns in the healthy and sick database.\n",
    "print(\"Let's allign these values: \")\n",
    "print(healthy_df['weekday'].unique())\n",
    "print(asthma_df['weekday'].unique())\n",
    "print()\n",
    "print(healthy_df['dayType'].unique())\n",
    "print(asthma_df['dayType'].unique())\n",
    "print()\n",
    "print(healthy_df['school_yes_no'].unique())\n",
    "print(asthma_df['school_yes_no'].unique())\n",
    "print()\n",
    "print(healthy_df['sex'].unique())\n",
    "print(asthma_df['sex'].unique())\n",
    "print()\n",
    "print(healthy_df['school_year'].unique())\n",
    "print(asthma_df['school_year'].unique())\n",
    "print()\n",
    "print(healthy_df['sportsyesno'].unique())\n",
    "print(asthma_df['sportsyesno'].unique())\n",
    "print()\n",
    "print(healthy_df['urbanisation'].unique())\n",
    "print(asthma_df['urbanisation'].unique())\n",
    "print()\n",
    "print(healthy_df['grade_fev1'].unique())\n",
    "print(asthma_df['grade_fev1'].unique())\n",
    "print()\n",
    "print(healthy_df['grade_fvc'].unique())\n",
    "print(asthma_df['grade_fvc'].unique())\n",
    "print()\n",
    "print(healthy_df['fev1_ratio_best'].unique())\n",
    "print(asthma_df['fev1_ratio_best'].unique())\n",
    "print(\"I am not sure why there are only true or nans here???\")\n",
    "print()\n",
    "print(healthy_df['screentime'].unique())\n",
    "print(asthma_df['screentime'].unique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45abca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# school_yes_no\n",
    "# for healthy: school, daycare or neither\n",
    "# for asthma: yes or no (school)\n",
    "# Decision: school and daycare are the same class\n",
    "# note that nan will be also be a category in the one-hot encoding (unknown)\n",
    "healthy_df['school_yes_no'] = healthy_df['school_yes_no'].replace({'Neither': 'no', 'Day Care': 'yes', 'School': 'yes'})\n",
    "asthma_df['school_yes_no'] = asthma_df['school_yes_no'].replace({'Nee': 'no', 'Ja': 'yes'})\n",
    "\n",
    "# sex\n",
    "# it doesnt make sense to one hot encode nan for one subject \n",
    "# this won't improve classification, we will have to assume a gender \n",
    "# Women are more likely to classify as non-binary --> assume female\n",
    "# https://www.pewresearch.org/social-trends/2022/06/28/americans-complex-views-on-gender-identity-and-transgender-issues/\n",
    "asthma_df['sex'] = asthma_df['sex'].fillna('Female')\n",
    "\n",
    "# school year\n",
    "# I think it will be best to drop this its likely to different in each data set \n",
    "healthy_df = healthy_df.drop('school_year', axis=1)\n",
    "asthma_df = asthma_df.drop('school_year', axis=1)\n",
    "\n",
    "# sports_yes_no\n",
    "# A couple subjects didn't fill this in, I think it is a fair assumption to made that \n",
    "# if they didn't fill it in than they didn't do sports\n",
    "asthma_df['sportsyesno'] = asthma_df['sportsyesno'].fillna('No')\n",
    "\n",
    "# Urbanization\n",
    "# Decision: Extremely and very will be merged to extremely urbanized\n",
    "# moderately and little urbanized will be merged to not extremely urbanized\n",
    "healthy_df['urbanisation'].replace({'Very urbanised': 'Extremely urbanised',\n",
    "                                    'Moderately urbanised': 'Not extremely urbanised', \n",
    "                                    'Little urbanised': 'Not extremely urbanised'}, \n",
    "                                   inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc410e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"new classes (they have to be the same): \")\n",
    "print(healthy_df['weekday'].unique())\n",
    "print(asthma_df['weekday'].unique())\n",
    "print()\n",
    "print(healthy_df['dayType'].unique())\n",
    "print(asthma_df['dayType'].unique())\n",
    "print()\n",
    "print(healthy_df['school_yes_no'].unique())\n",
    "print(asthma_df['school_yes_no'].unique())\n",
    "print()\n",
    "print(healthy_df['sex'].unique())\n",
    "print(asthma_df['sex'].unique())\n",
    "print()\n",
    "print(healthy_df['sportsyesno'].unique())\n",
    "print(asthma_df['sportsyesno'].unique())\n",
    "print()\n",
    "print(healthy_df['urbanisation'].unique())\n",
    "print(asthma_df['urbanisation'].unique())\n",
    "print()\n",
    "print(healthy_df['grade_fev1'].unique())\n",
    "print(asthma_df['grade_fev1'].unique())\n",
    "print()\n",
    "print(healthy_df['grade_fvc'].unique())\n",
    "print(asthma_df['grade_fvc'].unique())\n",
    "print()\n",
    "print(healthy_df['fev1_ratio_best'].unique())\n",
    "print(asthma_df['fev1_ratio_best'].unique())\n",
    "print(\"I am not sure why there are only true or nans here???\")\n",
    "print()\n",
    "print(healthy_df['screentime'].unique())\n",
    "print(asthma_df['screentime'].unique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7678a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "one_hot_asthma = pd.get_dummies(asthma_df[['weekday', 'dayType', 'school_yes_no', 'sex', 'sportsyesno', 'urbanisation',\n",
    "                                          'grade_fev1', 'grade_fvc', 'screentime']])\n",
    "one_hot_healthy = pd.get_dummies(healthy_df[['weekday', 'dayType', 'school_yes_no', 'sex', 'sportsyesno', 'urbanisation',\n",
    "                                          'grade_fev1', 'grade_fvc', 'screentime']])\n",
    "\n",
    "# Merging\n",
    "asthma_df = pd.concat([asthma_df, one_hot_asthma], axis=1)\n",
    "healthy_df = pd.concat([healthy_df, one_hot_healthy], axis=1)\n",
    "\n",
    "# Make sure to drop old columns (they are replaced with the hot-encoded cols)\n",
    "healthy_df = healthy_df.drop(columns=['weekday', 'dayType', 'school_yes_no', 'sex', 'sportsyesno', 'urbanisation',\n",
    "                                          'grade_fev1', 'grade_fvc', 'screentime'])\n",
    "asthma_df = asthma_df.drop(columns=['weekday', 'dayType', 'school_yes_no', 'sex', 'sportsyesno', 'urbanisation',\n",
    "                                          'grade_fev1', 'grade_fvc', 'screentime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bc962e",
   "metadata": {},
   "source": [
    "# Result from one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb79004",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4abc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "asthma_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eef24c",
   "metadata": {},
   "source": [
    "# Setting the columns equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e59a778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns in asthma_df that aren't already in healthy_df\n",
    "asthma_df = asthma_df.drop(columns=asthma_df.columns.difference(healthy_df.columns))\n",
    "\n",
    "# Sort columns \n",
    "asthma_df = asthma_df.reindex(columns=healthy_df.columns)\n",
    "\n",
    "# Assert the columns are the same\n",
    "assert all(healthy_df.columns == asthma_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fd09a8",
   "metadata": {},
   "source": [
    "# Booleans to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73edb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will change the booleans from the hot encoding to 0 or 1, while preserving all other data as floats\n",
    "healthy_df = healthy_df.astype(float)\n",
    "asthma_df = asthma_df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca677f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401d0281",
   "metadata": {},
   "outputs": [],
   "source": [
    "asthma_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cf1967",
   "metadata": {},
   "source": [
    "# Dealing with NaN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2863edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "asthma_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4cfa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35df453",
   "metadata": {},
   "source": [
    "# Removing columns with too much missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70fc4b4",
   "metadata": {},
   "source": [
    "# healthy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a484c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute for all the columns, the percentages of Nan per column\n",
    "# We will drop the columns that have more than 40% Nan\n",
    "percentNan = []\n",
    "columns_to_remove = []\n",
    "for col in healthy_df.columns:\n",
    "    nan_percentage = healthy_df[col].isnull().sum() / len(healthy_df[col]) * 100\n",
    "    percentNan.append((nan_percentage, col))\n",
    "\n",
    "percentNan.sort(reverse=True)\n",
    "\n",
    "print(\"Removed cols\")\n",
    "for el in percentNan:\n",
    "    if el[0] > 40:\n",
    "        columns_to_remove.append(el[1])\n",
    "        print(el)\n",
    "\n",
    "# Remove the column in both dataframes\n",
    "healthy_df = healthy_df.drop(columns=columns_to_remove) \n",
    "asthma_df = asthma_df.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11303100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute for all the columns, the percentages of Nan per column\n",
    "# We will drop the columns that have more than 40% Nan\n",
    "percentNan = []\n",
    "columns_to_remove = []\n",
    "for col in asthma_df.columns:\n",
    "    nan_percentage = asthma_df[col].isnull().sum() / len(asthma_df[col]) * 100\n",
    "    percentNan.append((nan_percentage, col))\n",
    "\n",
    "percentNan.sort(reverse=True)\n",
    "\n",
    "print(\"Removed cols\")\n",
    "for el in percentNan:\n",
    "    if el[0] > 40:\n",
    "        columns_to_remove.append(el[1])\n",
    "        print(el)\n",
    "        \n",
    "# Remove the column in both dataframes\n",
    "healthy_df = healthy_df.drop(columns=columns_to_remove)\n",
    "asthma_df = asthma_df.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f897e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50ea9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "asthma_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b02589",
   "metadata": {},
   "source": [
    "# Model based imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3a75f8",
   "metadata": {},
   "source": [
    "# healthy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b923d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform MICE imputation\n",
    "mice_imputer = IterativeImputer()\n",
    "imputed_data = mice_imputer.fit_transform(healthy_df)\n",
    "\n",
    "# Convert the imputed data array back to a DataFrame\n",
    "healthy_df = pd.DataFrame(imputed_data, columns=healthy_df.columns)\n",
    "\n",
    "# Display the imputed DataFrame\n",
    "healthy_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f0fc5a",
   "metadata": {},
   "source": [
    "# asthma_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5ba964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform MICE imputation\n",
    "mice_imputer2 = IterativeImputer()\n",
    "imputed_data2 = mice_imputer2.fit_transform(asthma_df)\n",
    "\n",
    "# Convert the imputed data array back to a DataFrame\n",
    "asthma_df = pd.DataFrame(imputed_data2, columns=asthma_df.columns)\n",
    "\n",
    "# Display the imputed DataFrame\n",
    "asthma_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c68df4",
   "metadata": {},
   "source": [
    "# Store dataframe as csv to test on models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5ce88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '../..'  # Specify the absolute path to the parent directory of the data directory\n",
    "subdirectory = 'Preprocessed'  # Name of the subdirectory\n",
    "\n",
    "# Create the subdirectory if it doesn't exist\n",
    "subdirectory_path = os.path.join(data_directory, 'Data', subdirectory)\n",
    "os.makedirs(subdirectory_path, exist_ok=True)\n",
    "\n",
    "# Save the preprocessed DataFrames as CSV files in the subdirectory\n",
    "asthma_df.to_csv(os.path.join(subdirectory_path, 'preprocessed_MICE_asthma_normal_Eventdate.csv'), index=False)\n",
    "healthy_df.to_csv(os.path.join(subdirectory_path, 'preprocessed_MICE_healthy_normal_Eventdate.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f8df10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
