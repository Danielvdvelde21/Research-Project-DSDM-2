{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97455c2a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7253ca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a48c33",
   "metadata": {},
   "source": [
    "# Scaling and Removing EventDay for one classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06149514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_models(df):              \n",
    "    # Get rid of asthma attack days \n",
    "    df_withoutRowEventDay = df[df['EventDay'] == 0]\n",
    "    \n",
    "    # Remove now usless EventDay column\n",
    "    df_withoutColEventDay = df_withoutRowEventDay.drop(['EventDay'], axis = 1)\n",
    "\n",
    "    # Initialize the StandardScaler and scale the dataframe\n",
    "    scaler = StandardScaler()\n",
    "    scaled_df = pd.DataFrame(scaler.fit_transform(df_withoutColEventDay), columns=df_withoutColEventDay.columns)\n",
    "    \n",
    "    '''\n",
    "    Important note!\n",
    "    Really important to use a random state here\n",
    "    Since the number of exacerbations is really low we should create multiple samples of the train test split\n",
    "    '''\n",
    "    \n",
    "    X_train, X_test = train_test_split(scaled_df, test_size=0.2)\n",
    "\n",
    "    return df_withoutColEventDay, X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c30ed56",
   "metadata": {},
   "source": [
    "# k-Means Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1314ea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggested_no_of_clusters(min_clusters, max_clusters):\n",
    "    # Initialize lists to store the number of clusters and corresponding WCSS values\n",
    "    num_clusters = []\n",
    "    wcss_values = []\n",
    "\n",
    "    # Perform clustering for different numbers of clusters\n",
    "    for k in range(min_clusters, max_clusters + 1):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "        kmeans.fit(df)\n",
    "\n",
    "        # Compute the within-cluster sum of squares (WCSS)\n",
    "        wcss = kmeans.inertia_\n",
    "\n",
    "        # Append the number of clusters and WCSS values to the lists\n",
    "        num_clusters.append(k)\n",
    "        wcss_values.append(wcss)\n",
    "\n",
    "    # Calculate the differences between consecutive WCSS values\n",
    "    wcss_diff = [wcss_values[i] - wcss_values[i-1] for i in range(1, len(wcss_values))]\n",
    "\n",
    "    # Find the index of the maximum difference\n",
    "    max_diff_index = wcss_diff.index(max(wcss_diff))\n",
    "\n",
    "    # Suggested number of clusters\n",
    "    suggested_clusters = num_clusters[max_diff_index]\n",
    "\n",
    "    print(\"Suggested number of clusters:\", suggested_clusters)\n",
    "\n",
    "    \n",
    "# TODO can refine clusters for diffeent data sets\n",
    "# suggested_no_of_clusters(data_train, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea7b9593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(df, data_train, data_pred, num_clusters=5, threshold=10):\n",
    "    # Select relevant columns for clustering\n",
    "    columns_to_cluster = data_train.columns\n",
    "\n",
    "    # Extract the subset of data for clustering from training DataFrame\n",
    "    data_for_clustering = data_train[columns_to_cluster]\n",
    "\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    data_for_clustering_standardized = scaler.fit_transform(data_for_clustering)\n",
    "\n",
    "    # Apply k-means clustering on training data\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    kmeans.fit(data_for_clustering_standardized)\n",
    "\n",
    "    # Get the cluster labels for training data\n",
    "    training_cluster_labels = kmeans.labels_\n",
    "\n",
    "    # Assign cluster labels to the training DataFrame\n",
    "    data_train['ClusterLabel'] = training_cluster_labels\n",
    "\n",
    "    # Check the distribution of clusters in training data\n",
    "    training_cluster_counts = data_train['ClusterLabel'].value_counts()\n",
    "\n",
    "    # Calculate cluster means on training data\n",
    "    training_cluster_means = data_train.groupby('ClusterLabel').mean()\n",
    "\n",
    "\n",
    "\n",
    "    # Extract the subset of data for anomaly prediction from predicting DataFrame\n",
    "    data_for_prediction = data_pred[columns_to_cluster]\n",
    "\n",
    "    # Standardize the data for prediction using the same scaler as training\n",
    "    data_for_prediction_standardized = scaler.transform(data_for_prediction)\n",
    "\n",
    "    # Get the cluster labels for prediction data\n",
    "    prediction_cluster_labels = kmeans.predict(data_for_prediction_standardized)\n",
    "\n",
    "    # Assign cluster labels to the predicting DataFrame\n",
    "    data_pred['ClusterLabel'] = prediction_cluster_labels\n",
    "\n",
    "    # Check the distribution of clusters in predicting data\n",
    "    prediction_cluster_counts = data_pred['ClusterLabel'].value_counts()\n",
    "\n",
    "    # Detect anomalies based on cluster means\n",
    "    anomaly_rows = []\n",
    "    for index, row in data_pred.iterrows():\n",
    "        cluster_label = row['ClusterLabel']\n",
    "        features = row[columns_to_cluster]\n",
    "        cluster_mean = training_cluster_means.loc[cluster_label]\n",
    "        if any(abs(features - cluster_mean) > threshold):\n",
    "            anomaly_rows.append(index)\n",
    "\n",
    "    # detected anomalies\n",
    "    anomalies = data_pred.loc[anomaly_rows]\n",
    "    \n",
    "    df['Anomalies_KMeans'] = -1  # Initialize the column with -1 values\n",
    "    df.loc[anomalies.index, 'Anomalies_KMeans'] = 1  # Set the corresponding anomalies as 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6ad95b",
   "metadata": {},
   "source": [
    "# Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0651b9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iforest(df, data_train, data_pred, outliers_fraction=0.5):\n",
    "    # Train\n",
    "    ifo = IsolationForest(contamination = outliers_fraction)\n",
    "    ifo.fit(data_train)\n",
    "\n",
    "    # Predict\n",
    "    df['Anomalies_IF'] = pd.Series(ifo.predict(data_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971ba10e",
   "metadata": {},
   "source": [
    "# OSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1d1d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocsvm(df, data_train, data_pred, outliers_fraction=0.9):\n",
    "    # Train\n",
    "    osvm = OneClassSVM(nu = outliers_fraction, kernel = 'sigmoid')\n",
    "    osvm.fit(data_train)\n",
    "\n",
    "    # Predict\n",
    "    df['Anomalies_OSVM'] = pd.Series(osvm.predict(data_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec48e78b",
   "metadata": {},
   "source": [
    "# Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eb86b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_of(df, data_train, data_pred, outliers_fraction=0.3):\n",
    "    # Train\n",
    "    lof = LocalOutlierFactor(contamination=outliers_fraction)\n",
    "    lof.fit(data_train)\n",
    "\n",
    "    # Predict\n",
    "    df['Anomalies_LOF'] = pd.Series(lof.fit_predict(data_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f359f12d",
   "metadata": {},
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b5c3dc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def autoencoders(df, df_withoutColEventDay, train, test):\n",
    "    # Define the shape of the input data\n",
    "    input_dim = train.shape[1]\n",
    "\n",
    "    # Define the architecture of the autoencoder\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoder = Dense(32, activation='relu')(input_layer)  # Encoding layer\n",
    "    decoder = Dense(input_dim, activation='linear')(encoder)  # Decoding layer\n",
    "\n",
    "    # Create the autoencoder model\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "\n",
    "    # Compile the model\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Train the autoencoder\n",
    "    autoencoder.fit(train, train, epochs=50, batch_size=32, validation_data=(test, test))\n",
    "\n",
    "    # Use the trained autoencoder to predict on the test dataset\n",
    "    reconstructed_data = autoencoder.predict(test)\n",
    "\n",
    "    # Calculate the mean squared error (MSE) between the original and reconstructed data\n",
    "    mse = np.mean(np.power(test - reconstructed_data, 2), axis=1)\n",
    "\n",
    "    # Define a threshold to determine outliers\n",
    "    threshold = np.mean(mse) + 3 * np.std(mse)  # Adjust the multiplier (3) as per your requirements\n",
    "\n",
    "    # Map outliers as -1 and inliers as 1\n",
    "    outliers = np.where(mse > threshold, -1, 1)\n",
    "\n",
    "    # Return anomalies\n",
    "    anomalies = test.copy()\n",
    "    anomalies['Anomaly'] = outliers\n",
    "    \n",
    "    '''# Fill the anomalies back into the original dataframe\n",
    "    df['Anomaly'] = 1  # Initialize all rows as inliers (1)\n",
    "    df.loc[df_withoutColEventDay.index, 'Anomaly'] = anomalies['Anomaly'].values'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025298cb",
   "metadata": {},
   "source": [
    "# Deep Support Vector Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1d6d996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsvdd(df, data_train, data_pred):\n",
    "    # Convert the preprocessed data to a PyTorch tensor\n",
    "    tensor_data = torch.tensor(data_train.values, dtype=torch.float32)\n",
    "    tensor_data_pred = torch.tensor(data_pred.values, dtype=torch.float32)\n",
    "\n",
    "    # Create a DataLoader for efficient batch processing\n",
    "    batch_size = 64\n",
    "    data_loader = DataLoader(TensorDataset(tensor_data), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Define the DSVDD model\n",
    "    class Autoencoder(nn.Module):\n",
    "        def __init__(self, input_dim, hidden_dim):\n",
    "            super(Autoencoder, self).__init__()\n",
    "            self.encoder = nn.Sequential(\n",
    "                nn.Linear(input_dim, hidden_dim),\n",
    "                nn.ReLU(True),\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.ReLU(True),\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.ReLU(True)\n",
    "            )\n",
    "            self.decoder = nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.ReLU(True),\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.ReLU(True),\n",
    "                nn.Linear(hidden_dim, input_dim),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            encoded = self.encoder(x)\n",
    "            decoded = self.decoder(encoded)\n",
    "            return encoded, decoded\n",
    "\n",
    "    # Train the DSVDD model\n",
    "    input_dim = data_train.shape[1]\n",
    "    hidden_dim = 64\n",
    "    num_epochs = 50\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    autoencoder = Autoencoder(input_dim, hidden_dim)\n",
    "    optimizer = optim.Adam(autoencoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    autoencoder.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, data_batch in enumerate(data_loader):\n",
    "            optimizer.zero_grad()\n",
    "            inputs = data_batch[0]\n",
    "\n",
    "            encoded, decoded = autoencoder(inputs)\n",
    "\n",
    "            # Reconstruction loss\n",
    "            reconstruction_loss = nn.MSELoss()(decoded, inputs)\n",
    "\n",
    "            loss = reconstruction_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Extract the learned features\n",
    "    autoencoder.eval()\n",
    "    with torch.no_grad():\n",
    "        encoded_data, _ = autoencoder(tensor_data)\n",
    "        encoded_data_pred, _ = autoencoder(tensor_data_pred)\n",
    "\n",
    "    # Train an SVM/OSVM using the learned features\n",
    "    svm = OneClassSVM(kernel='sigmoid', nu=0.9)  # Adjust the hyperparameters as needed\n",
    "    svm.fit(encoded_data.detach().numpy())\n",
    "\n",
    "    # Detect anomalies\n",
    "    anomalies = df[svm.predict(encoded_data_pred.detach().numpy()) == -1]  # Filter the original DataFrame for anomalies\n",
    "\n",
    "    df['Anomalies_DSVDD'] = 1\n",
    "    df.loc[anomalies.index, 'Anomalies_DSVDD'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ad6e98",
   "metadata": {},
   "source": [
    "# MICE\n",
    "Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1aa9961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move up 2 directories\n",
    "data_directory = '../..' \n",
    "\n",
    "# Load the CSV files\n",
    "asthma_df = pd.read_csv(os.path.join(data_directory, 'Data\\Preprocessed', 'preprocessed_MICE_asthma.csv'))\n",
    "healthy_df = pd.read_csv(os.path.join(data_directory, 'Data\\Preprocessed', 'preprocessed_MICE_healthy.csv'))\n",
    "\n",
    "# Merged df\n",
    "merged_df = pd.concat([asthma_df, healthy_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01cc754d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DayNo</th>\n",
       "      <th>Age</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>BMI_SDS</th>\n",
       "      <th>PedsQL_score_baseline</th>\n",
       "      <th>stepsTotalDaily</th>\n",
       "      <th>steps_hour_max</th>\n",
       "      <th>steps07</th>\n",
       "      <th>steps08</th>\n",
       "      <th>steps09</th>\n",
       "      <th>steps10</th>\n",
       "      <th>steps11</th>\n",
       "      <th>steps12</th>\n",
       "      <th>steps13</th>\n",
       "      <th>steps14</th>\n",
       "      <th>steps15</th>\n",
       "      <th>steps16</th>\n",
       "      <th>steps17</th>\n",
       "      <th>steps18</th>\n",
       "      <th>steps19</th>\n",
       "      <th>steps20</th>\n",
       "      <th>HR05Perc</th>\n",
       "      <th>HR95Perc</th>\n",
       "      <th>HRMinSleep</th>\n",
       "      <th>HRMaxSleep</th>\n",
       "      <th>AVGHR_daily</th>\n",
       "      <th>AVGHR_sleep</th>\n",
       "      <th>AVGHR_wake</th>\n",
       "      <th>HR00</th>\n",
       "      <th>HR01</th>\n",
       "      <th>HR02</th>\n",
       "      <th>HR03</th>\n",
       "      <th>HR04</th>\n",
       "      <th>HR05</th>\n",
       "      <th>HR06</th>\n",
       "      <th>HR07</th>\n",
       "      <th>HR08</th>\n",
       "      <th>HR09</th>\n",
       "      <th>HR10</th>\n",
       "      <th>HR11</th>\n",
       "      <th>HR12</th>\n",
       "      <th>HR13</th>\n",
       "      <th>HR14</th>\n",
       "      <th>HR15</th>\n",
       "      <th>HR16</th>\n",
       "      <th>HR17</th>\n",
       "      <th>HR18</th>\n",
       "      <th>HR19</th>\n",
       "      <th>HR20</th>\n",
       "      <th>HR21</th>\n",
       "      <th>HR22</th>\n",
       "      <th>HR23</th>\n",
       "      <th>wear05H</th>\n",
       "      <th>wear16H</th>\n",
       "      <th>wear24H</th>\n",
       "      <th>awakeDuration</th>\n",
       "      <th>lightSleepDuration</th>\n",
       "      <th>deepSleepDuration</th>\n",
       "      <th>wakeUpCount</th>\n",
       "      <th>FG</th>\n",
       "      <th>FHX</th>\n",
       "      <th>FHN</th>\n",
       "      <th>TG</th>\n",
       "      <th>TN</th>\n",
       "      <th>TX</th>\n",
       "      <th>SQ</th>\n",
       "      <th>SP</th>\n",
       "      <th>DR</th>\n",
       "      <th>RH</th>\n",
       "      <th>RHX</th>\n",
       "      <th>EventDay</th>\n",
       "      <th>weekday_Fri</th>\n",
       "      <th>weekday_Mon</th>\n",
       "      <th>weekday_Sat</th>\n",
       "      <th>weekday_Sun</th>\n",
       "      <th>weekday_Thu</th>\n",
       "      <th>weekday_Tue</th>\n",
       "      <th>weekday_Wed</th>\n",
       "      <th>dayType_holiday</th>\n",
       "      <th>dayType_school</th>\n",
       "      <th>dayType_weekend</th>\n",
       "      <th>school_yes_no_no</th>\n",
       "      <th>school_yes_no_yes</th>\n",
       "      <th>sex_Female</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>sportsyesno_No</th>\n",
       "      <th>sportsyesno_Yes</th>\n",
       "      <th>urbanisation_Extremely urbanised</th>\n",
       "      <th>urbanisation_Not extremely urbanised</th>\n",
       "      <th>grade_fev1_A</th>\n",
       "      <th>grade_fev1_B</th>\n",
       "      <th>grade_fev1_C</th>\n",
       "      <th>grade_fev1_D</th>\n",
       "      <th>grade_fev1_E</th>\n",
       "      <th>grade_fev1_F</th>\n",
       "      <th>grade_fev1_U</th>\n",
       "      <th>grade_fvc_A</th>\n",
       "      <th>grade_fvc_B</th>\n",
       "      <th>grade_fvc_C</th>\n",
       "      <th>grade_fvc_D</th>\n",
       "      <th>grade_fvc_E</th>\n",
       "      <th>grade_fvc_F</th>\n",
       "      <th>grade_fvc_U</th>\n",
       "      <th>screentime_0-30 min</th>\n",
       "      <th>screentime_0.5-1 hours</th>\n",
       "      <th>screentime_1-2 hours</th>\n",
       "      <th>screentime_2-4 hours</th>\n",
       "      <th>screentime_&gt; 4 hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>51.9</td>\n",
       "      <td>163.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>847826087.0</td>\n",
       "      <td>3723.0</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>147.660462</td>\n",
       "      <td>198.589585</td>\n",
       "      <td>63.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>449.061499</td>\n",
       "      <td>205.326828</td>\n",
       "      <td>605.0</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>514.09455</td>\n",
       "      <td>82.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>75.312548</td>\n",
       "      <td>94.0</td>\n",
       "      <td>72.354658</td>\n",
       "      <td>70.32749</td>\n",
       "      <td>72.162935</td>\n",
       "      <td>72.645209</td>\n",
       "      <td>70.346684</td>\n",
       "      <td>70.987121</td>\n",
       "      <td>73.239849</td>\n",
       "      <td>85.81755</td>\n",
       "      <td>94.229593</td>\n",
       "      <td>91.550898</td>\n",
       "      <td>93.735671</td>\n",
       "      <td>120.0</td>\n",
       "      <td>96.217727</td>\n",
       "      <td>93.848718</td>\n",
       "      <td>102.29268</td>\n",
       "      <td>95.356064</td>\n",
       "      <td>94.624175</td>\n",
       "      <td>89.8</td>\n",
       "      <td>83.4</td>\n",
       "      <td>87.8</td>\n",
       "      <td>91.5</td>\n",
       "      <td>93.30</td>\n",
       "      <td>77.1</td>\n",
       "      <td>78.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>16800.0</td>\n",
       "      <td>16440.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>51.9</td>\n",
       "      <td>163.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>847826087.0</td>\n",
       "      <td>10015.0</td>\n",
       "      <td>4355.0</td>\n",
       "      <td>41.399402</td>\n",
       "      <td>607.000000</td>\n",
       "      <td>580.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>181.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>161.00000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>1146.0</td>\n",
       "      <td>4355.0</td>\n",
       "      <td>722.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>102.0</td>\n",
       "      <td>73.600000</td>\n",
       "      <td>75.20000</td>\n",
       "      <td>70.750000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>70.300000</td>\n",
       "      <td>82.300000</td>\n",
       "      <td>78.00000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>129.800000</td>\n",
       "      <td>95.1</td>\n",
       "      <td>91.600000</td>\n",
       "      <td>105.358749</td>\n",
       "      <td>108.50000</td>\n",
       "      <td>85.250000</td>\n",
       "      <td>93.400000</td>\n",
       "      <td>95.8</td>\n",
       "      <td>101.8</td>\n",
       "      <td>142.3</td>\n",
       "      <td>107.8</td>\n",
       "      <td>104.20</td>\n",
       "      <td>91.8</td>\n",
       "      <td>93.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>22200.0</td>\n",
       "      <td>11760.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>51.9</td>\n",
       "      <td>163.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>847826087.0</td>\n",
       "      <td>3811.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>561.000000</td>\n",
       "      <td>159.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>591.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>456.00000</td>\n",
       "      <td>155.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>96.0</td>\n",
       "      <td>79.100000</td>\n",
       "      <td>73.10000</td>\n",
       "      <td>80.300000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>76.100000</td>\n",
       "      <td>74.600000</td>\n",
       "      <td>78.100000</td>\n",
       "      <td>98.50000</td>\n",
       "      <td>103.400000</td>\n",
       "      <td>100.500000</td>\n",
       "      <td>109.600000</td>\n",
       "      <td>100.6</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>86.50000</td>\n",
       "      <td>88.600000</td>\n",
       "      <td>102.800000</td>\n",
       "      <td>78.2</td>\n",
       "      <td>85.2</td>\n",
       "      <td>94.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>89.25</td>\n",
       "      <td>96.5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>19260.0</td>\n",
       "      <td>12360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>62.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>8.2</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>51.9</td>\n",
       "      <td>163.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>847826087.0</td>\n",
       "      <td>4346.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>119.919027</td>\n",
       "      <td>515.000000</td>\n",
       "      <td>673.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>322.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>523.00000</td>\n",
       "      <td>61.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>93.0</td>\n",
       "      <td>77.100000</td>\n",
       "      <td>79.80000</td>\n",
       "      <td>72.600000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>80.200000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>73.600000</td>\n",
       "      <td>79.00000</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>103.500000</td>\n",
       "      <td>106.400000</td>\n",
       "      <td>95.5</td>\n",
       "      <td>106.200000</td>\n",
       "      <td>98.200000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>84.300000</td>\n",
       "      <td>86.800000</td>\n",
       "      <td>97.2</td>\n",
       "      <td>74.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>82.4</td>\n",
       "      <td>96.10</td>\n",
       "      <td>90.8</td>\n",
       "      <td>78.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>17041.0</td>\n",
       "      <td>19619.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>63.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>51.9</td>\n",
       "      <td>163.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>847826087.0</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>1324.0</td>\n",
       "      <td>27.834972</td>\n",
       "      <td>223.003456</td>\n",
       "      <td>50.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>1324.000000</td>\n",
       "      <td>388.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>101.00000</td>\n",
       "      <td>91.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>83.0</td>\n",
       "      <td>83.300000</td>\n",
       "      <td>77.60000</td>\n",
       "      <td>75.100000</td>\n",
       "      <td>76.200000</td>\n",
       "      <td>72.600000</td>\n",
       "      <td>75.800000</td>\n",
       "      <td>73.800000</td>\n",
       "      <td>68.00000</td>\n",
       "      <td>74.800000</td>\n",
       "      <td>65.400000</td>\n",
       "      <td>94.400000</td>\n",
       "      <td>85.7</td>\n",
       "      <td>77.250000</td>\n",
       "      <td>86.500000</td>\n",
       "      <td>78.00000</td>\n",
       "      <td>76.600000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>89.1</td>\n",
       "      <td>92.2</td>\n",
       "      <td>110.6</td>\n",
       "      <td>77.4</td>\n",
       "      <td>81.10</td>\n",
       "      <td>76.5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>17340.0</td>\n",
       "      <td>15300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>98.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DayNo   Age  weight  height  BMI_SDS  PedsQL_score_baseline  \\\n",
       "0    0.0  15.0    51.9   163.2     -0.1            847826087.0   \n",
       "1    1.0  15.0    51.9   163.2     -0.1            847826087.0   \n",
       "2    2.0  15.0    51.9   163.2     -0.1            847826087.0   \n",
       "3    3.0  15.0    51.9   163.2     -0.1            847826087.0   \n",
       "4    4.0  15.0    51.9   163.2     -0.1            847826087.0   \n",
       "\n",
       "   stepsTotalDaily  steps_hour_max     steps07     steps08  steps09  steps10  \\\n",
       "0           3723.0          1640.0  147.660462  198.589585     63.0    137.0   \n",
       "1          10015.0          4355.0   41.399402  607.000000    580.0    325.0   \n",
       "2           3811.0           727.0   63.000000  561.000000    159.0    356.0   \n",
       "3           4346.0           673.0  119.919027  515.000000    673.0    377.0   \n",
       "4           3270.0          1324.0   27.834972  223.003456     50.0     92.0   \n",
       "\n",
       "      steps11      steps12  steps13  steps14    steps15  steps16  steps17  \\\n",
       "0  449.061499   205.326828    605.0   1640.0  514.09455     82.0    451.0   \n",
       "1  180.000000   322.000000    181.0    491.0  161.00000     10.0    744.0   \n",
       "2   26.000000   591.000000    109.0    114.0  456.00000    155.0    727.0   \n",
       "3  490.000000   192.000000    322.0    180.0  523.00000     61.0    359.0   \n",
       "4  167.000000  1324.000000    388.0    166.0  101.00000     91.0      6.0   \n",
       "\n",
       "   steps18  steps19  steps20  HR05Perc  HR95Perc  HRMinSleep  HRMaxSleep  \\\n",
       "0    245.0    135.0    160.0      68.0     120.0        61.0        93.0   \n",
       "1   1146.0   4355.0    722.0      82.0     168.0        67.0       121.0   \n",
       "2     46.0    139.0    210.0      71.0     122.0        64.0       129.0   \n",
       "3    174.0     95.0    148.0      66.0     128.0        59.0       107.0   \n",
       "4    224.0    405.0     56.0      64.0     111.0        57.0        88.0   \n",
       "\n",
       "   AVGHR_daily  AVGHR_sleep  AVGHR_wake       HR00      HR01       HR02  \\\n",
       "0         90.0    75.312548        94.0  72.354658  70.32749  72.162935   \n",
       "1         94.0    76.000000       102.0  73.600000  75.20000  70.750000   \n",
       "2         90.0    77.000000        96.0  79.100000  73.10000  80.300000   \n",
       "3         88.0    75.000000        93.0  77.100000  79.80000  72.600000   \n",
       "4         81.0    77.000000        83.0  83.300000  77.60000  75.100000   \n",
       "\n",
       "        HR03       HR04       HR05       HR06      HR07        HR08  \\\n",
       "0  72.645209  70.346684  70.987121  73.239849  85.81755   94.229593   \n",
       "1  92.000000  76.000000  70.300000  82.300000  78.00000   99.000000   \n",
       "2  78.000000  76.100000  74.600000  78.100000  98.50000  103.400000   \n",
       "3  67.000000  80.200000  76.000000  73.600000  79.00000   98.500000   \n",
       "4  76.200000  72.600000  75.800000  73.800000  68.00000   74.800000   \n",
       "\n",
       "         HR09        HR10   HR11        HR12        HR13       HR14  \\\n",
       "0   91.550898   93.735671  120.0   96.217727   93.848718  102.29268   \n",
       "1  113.000000  129.800000   95.1   91.600000  105.358749  108.50000   \n",
       "2  100.500000  109.600000  100.6  105.000000  109.000000   86.50000   \n",
       "3  103.500000  106.400000   95.5  106.200000   98.200000  100.00000   \n",
       "4   65.400000   94.400000   85.7   77.250000   86.500000   78.00000   \n",
       "\n",
       "        HR15        HR16  HR17   HR18   HR19   HR20    HR21  HR22  HR23  \\\n",
       "0  95.356064   94.624175  89.8   83.4   87.8   91.5   93.30  77.1  78.6   \n",
       "1  85.250000   93.400000  95.8  101.8  142.3  107.8  104.20  91.8  93.0   \n",
       "2  88.600000  102.800000  78.2   85.2   94.0  100.0   89.25  96.5  82.0   \n",
       "3  84.300000   86.800000  97.2   74.0  107.0   82.4   96.10  90.8  78.2   \n",
       "4  76.600000   90.000000  89.1   92.2  110.6   77.4   81.10  76.5  82.0   \n",
       "\n",
       "   wear05H  wear16H  wear24H  awakeDuration  lightSleepDuration  \\\n",
       "0      0.0     69.0     54.0          660.0             16800.0   \n",
       "1    100.0    100.0    100.0          180.0             22200.0   \n",
       "2    100.0    100.0    100.0          300.0             19260.0   \n",
       "3    100.0    100.0    100.0         1140.0             17041.0   \n",
       "4    100.0    100.0    100.0          540.0             17340.0   \n",
       "\n",
       "   deepSleepDuration  wakeUpCount    FG   FHX  FHN    TG     TN    TX   SQ  \\\n",
       "0            16440.0          1.0   6.3   8.0  4.0  14.0   85.0  19.7  5.4   \n",
       "1            11760.0          0.0  10.0  12.0  8.0  11.3  100.0  13.1  0.2   \n",
       "2            12360.0          1.0   6.0   9.0  4.0   9.9   62.0  13.3  8.2   \n",
       "3            19619.0          1.0   6.9  10.0  4.0   9.5   63.0  11.7  3.2   \n",
       "4            15300.0          2.0   9.3  12.0  6.0  11.2   98.0  12.9  0.5   \n",
       "\n",
       "     SP   DR    RH   RHX  EventDay  weekday_Fri  weekday_Mon  weekday_Sat  \\\n",
       "0  58.0  0.0   0.0   0.0       0.0          0.0          0.0          0.0   \n",
       "1   2.0  0.9   2.0   1.0       0.0          0.0          0.0          0.0   \n",
       "2  89.0  0.0   0.0   0.0       0.0          0.0          0.0          0.0   \n",
       "3  35.0  0.0   0.0   0.0       0.0          1.0          0.0          0.0   \n",
       "4   5.0  5.5  38.0  10.0       0.0          0.0          0.0          1.0   \n",
       "\n",
       "   weekday_Sun  weekday_Thu  weekday_Tue  weekday_Wed  dayType_holiday  \\\n",
       "0          0.0          0.0          1.0          0.0              0.0   \n",
       "1          0.0          0.0          0.0          1.0              0.0   \n",
       "2          0.0          1.0          0.0          0.0              0.0   \n",
       "3          0.0          0.0          0.0          0.0              0.0   \n",
       "4          0.0          0.0          0.0          0.0              0.0   \n",
       "\n",
       "   dayType_school  dayType_weekend  school_yes_no_no  school_yes_no_yes  \\\n",
       "0             1.0              0.0               0.0                0.0   \n",
       "1             1.0              0.0               0.0                1.0   \n",
       "2             1.0              0.0               0.0                1.0   \n",
       "3             1.0              0.0               0.0                1.0   \n",
       "4             0.0              1.0               1.0                0.0   \n",
       "\n",
       "   sex_Female  sex_Male  sportsyesno_No  sportsyesno_Yes  \\\n",
       "0         1.0       0.0             0.0              1.0   \n",
       "1         1.0       0.0             0.0              1.0   \n",
       "2         1.0       0.0             0.0              1.0   \n",
       "3         1.0       0.0             0.0              1.0   \n",
       "4         1.0       0.0             0.0              1.0   \n",
       "\n",
       "   urbanisation_Extremely urbanised  urbanisation_Not extremely urbanised  \\\n",
       "0                               1.0                                   0.0   \n",
       "1                               1.0                                   0.0   \n",
       "2                               1.0                                   0.0   \n",
       "3                               1.0                                   0.0   \n",
       "4                               1.0                                   0.0   \n",
       "\n",
       "   grade_fev1_A  grade_fev1_B  grade_fev1_C  grade_fev1_D  grade_fev1_E  \\\n",
       "0           0.0           0.0           0.0           1.0           0.0   \n",
       "1           1.0           0.0           0.0           0.0           0.0   \n",
       "2           0.0           1.0           0.0           0.0           0.0   \n",
       "3           0.0           1.0           0.0           0.0           0.0   \n",
       "4           0.0           1.0           0.0           0.0           0.0   \n",
       "\n",
       "   grade_fev1_F  grade_fev1_U  grade_fvc_A  grade_fvc_B  grade_fvc_C  \\\n",
       "0           0.0           0.0          0.0          1.0          0.0   \n",
       "1           0.0           0.0          1.0          0.0          0.0   \n",
       "2           0.0           0.0          0.0          1.0          0.0   \n",
       "3           0.0           0.0          0.0          1.0          0.0   \n",
       "4           0.0           0.0          0.0          1.0          0.0   \n",
       "\n",
       "   grade_fvc_D  grade_fvc_E  grade_fvc_F  grade_fvc_U  screentime_0-30 min  \\\n",
       "0          0.0          0.0          0.0          0.0                  0.0   \n",
       "1          0.0          0.0          0.0          0.0                  0.0   \n",
       "2          0.0          0.0          0.0          0.0                  0.0   \n",
       "3          0.0          0.0          0.0          0.0                  0.0   \n",
       "4          0.0          0.0          0.0          0.0                  0.0   \n",
       "\n",
       "   screentime_0.5-1 hours  screentime_1-2 hours  screentime_2-4 hours  \\\n",
       "0                     0.0                   0.0                   0.0   \n",
       "1                     1.0                   0.0                   0.0   \n",
       "2                     1.0                   0.0                   0.0   \n",
       "3                     1.0                   0.0                   0.0   \n",
       "4                     1.0                   0.0                   0.0   \n",
       "\n",
       "   screentime_> 4 hours  \n",
       "0                   0.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cc9a011",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Preprocess for models\n",
    "df_withoutColEventDay, train, pred = preprocess_for_models(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e49c99d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run all models and store anomaly results in merged_df\n",
    "ocsvm(merged_df, train, pred)\n",
    "k_means(merged_df, train, pred)\n",
    "iforest(merged_df, train, pred)\n",
    "ocsvm(merged_df, train, pred)\n",
    "\n",
    "# Didnt get this to work yet\n",
    "# autoencoders(merged_df, df_withoutColEventDay, train, pred) \n",
    "# dsvdd(merged_df, train, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dddf1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalies_OSVM - EventDay:  0.0\n",
      "Anomalies_KMeans - EventDay:  0.0\n",
      "Anomalies_IF - EventDay:  0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Check the total number of 1s in 'EventDay'\n",
    "total_ones = merged_df['EventDay'].value_counts().get(1, 1)  # Set default value to 1 to avoid division by zero\n",
    "\n",
    "# Check if there is a 1 in 'EventDay' when there is a 1 in 'Anomalies_OSVM'\n",
    "osvm_eventday = merged_df['EventDay'][merged_df['Anomalies_OSVM'] == 1].value_counts().get(1, 0)\n",
    "osvm_ratio = osvm_eventday / total_ones\n",
    "\n",
    "# Check if there is a 1 in 'EventDay' when there is a 1 in 'Anomalies_KMeans'\n",
    "kmeans_eventday = merged_df['EventDay'][merged_df['Anomalies_KMeans'] == 1].value_counts().get(1, 0)\n",
    "kmeans_ratio = kmeans_eventday / total_ones\n",
    "\n",
    "# Check if there is a 1 in 'EventDay' when there is a 1 in 'Anomalies_IF'\n",
    "if_eventday = merged_df['EventDay'][merged_df['Anomalies_IF'] == 1].value_counts().get(1, 0)\n",
    "if_ratio = if_eventday / total_ones\n",
    "\n",
    "# Print the results\n",
    "print(\"Anomalies_OSVM - EventDay: \", osvm_ratio)\n",
    "print(\"Anomalies_KMeans - EventDay: \", kmeans_ratio)\n",
    "print(\"Anomalies_IF - EventDay: \", if_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e2c0cb",
   "metadata": {},
   "source": [
    "# TODO fix autencoders and dsvdd\n",
    "# Then try feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc69121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
